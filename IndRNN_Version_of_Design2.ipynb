{
  {
"cell_type": "markdown",
"metadata": {
"colab_type": "text",
"id": "view-in-github"
},
"source": [
"<a href=\"https://colab.research.google.com/github/Rezvious/Predicting-PDs-EEG-based-on-IndRNN/blob/main/IndRNN_Version_of_Design2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
]
},
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "fixed startpoint= 1000 - trial out- IndRNN Version of Design2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebi9sK96ShPc",
        "outputId": "59f5e7b4-29b9-48f7-a37d-0487fcad052c"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "import warnings\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import activations\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras import constraints\n",
        "from keras.engine import Layer\n",
        "from keras.engine import InputSpec\n",
        "from keras.legacy import interfaces\n",
        "from keras.layers import RNN\n",
        "# from keras.layers.recurrent import _generate_dropout_mask, _generate_dropout_ones\n",
        "\n",
        "class IndRNNCell(Layer):\n",
        "    \"\"\"Independently Recurrent Neural Networks Cell class.\n",
        "\n",
        "    Derived from the paper [Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN](https://arxiv.org/abs/1803.04831)\n",
        "    Ref: [Tensorflow implementation](https://github.com/batzner/indrnn)\n",
        "\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        recurrent_clip_min: Can be one of None, -1 or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, will calculate the clip value for `relu` activation\n",
        "        recurrent_clip_max: Can be one of None or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, will calculate the clip value for `relu` activation\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you pass None, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix, used for the linear transformation of the\n",
        "            recurrent state.\n",
        "            Can be `None` or an available initializer. Defaults to `None`.\n",
        "            If None, defaults to uniform initialization.\n",
        "            If None, and recurrent_clip_min/max is not None, then\n",
        "            it uses those clip values as for uniform initialization.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "        implementation: Implementation mode, must be 2.\n",
        "            Mode 1 will structure its operations as a larger number of\n",
        "            smaller dot products and additions, whereas mode 2 will\n",
        "            batch them into fewer, larger operations. These modes will\n",
        "            have different performance profiles on different hardware and\n",
        "            for different applications.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units,\n",
        "                 recurrent_clip_min=-1,\n",
        "                 recurrent_clip_max=-1,\n",
        "                 activation='relu',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer=None,\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 implementation=2,\n",
        "                 **kwargs):\n",
        "        super(IndRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "        if implementation != 2:\n",
        "            warnings.warn(\n",
        "                \"IndRNN only supports implementation 2 for the moment. Defaulting to implementation = 2\")\n",
        "            implementation = 2\n",
        "\n",
        "        if recurrent_clip_min is None or recurrent_clip_max is None:\n",
        "            recurrent_clip_min = None\n",
        "            recurrent_clip_max = None\n",
        "\n",
        "        self.units = units\n",
        "        self.recurrent_clip_min = recurrent_clip_min\n",
        "        self.recurrent_clip_max = recurrent_clip_max\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.recurrent_initializer = initializers.get(recurrent_initializer) \\\n",
        "                                     if recurrent_initializer is not None else None\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.recurrent_constraint = constraints.get(recurrent_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.dropout = min(1., max(0., dropout))\n",
        "        self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n",
        "        self.implementation = implementation\n",
        "        self.state_size = (self.units,)\n",
        "        self._dropout_mask = None\n",
        "        self._recurrent_masks = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1]\n",
        "\n",
        "        if self.recurrent_clip_min == -1 or self.recurrent_clip_max == -1:\n",
        "            self.recurrent_clip_min = 0.0\n",
        "\n",
        "            if hasattr(self, 'timesteps') and self.timesteps is not None:\n",
        "                self.recurrent_clip_max = pow(2.0, 1. / self.timesteps)\n",
        "            else:\n",
        "                warnings.warn(\"IndRNNCell: Number of timesteps could not be determined. \\n\"\n",
        "                              \"Defaulting to max clipping range of 1.0. \\n\"\n",
        "                              \"If this model was trained using a specific timestep during training, \"\n",
        "                              \"inference may be wrong due to this default setting.\\n\"\n",
        "                              \"Please ensure that you use the same number of timesteps during training \"\n",
        "                              \"and evaluation\")\n",
        "                self.recurrent_clip_max = 1.0\n",
        "\n",
        "        self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                      name='input_kernel',\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "\n",
        "        if self.recurrent_initializer is None:\n",
        "            if self.recurrent_clip_min is not None and self.recurrent_clip_max is not None:\n",
        "                initialization_value = min(self.recurrent_clip_max, 1.0)\n",
        "                self.recurrent_initializer = initializers.uniform(-initialization_value,\n",
        "                                                                  initialization_value)\n",
        "            else:\n",
        "                self.recurrent_initializer = initializers.uniform(-1.0, 1.0)\n",
        "\n",
        "        self.recurrent_kernel = self.add_weight(shape=(self.units,),\n",
        "                                                name='recurrent_kernel',\n",
        "                                                initializer=self.recurrent_initializer,\n",
        "                                                regularizer=self.recurrent_regularizer,\n",
        "                                                constraint=self.recurrent_constraint)\n",
        "\n",
        "        if self.recurrent_clip_min is not None and self.recurrent_clip_max is not None:\n",
        "            if abs(self.recurrent_clip_min):\n",
        "                abs_recurrent_kernel = K.abs(self.recurrent_kernel)\n",
        "                min_recurrent_kernel = K.maximum(abs_recurrent_kernel, abs(self.recurrent_clip_min))\n",
        "                self.recurrent_kernel = K.sign(self.recurrent_kernel) * min_recurrent_kernel\n",
        "\n",
        "            self.recurrent_kernel = K.clip(self.recurrent_kernel,\n",
        "                                           self.recurrent_clip_min,\n",
        "                                           self.recurrent_clip_max)\n",
        "\n",
        "        if self.use_bias:\n",
        "            bias_initializer = self.bias_initializer\n",
        "\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        name='bias',\n",
        "                                        initializer=bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states, training=None):\n",
        "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
        "            self._dropout_mask = _generate_dropout_mask(\n",
        "                _generate_dropout_ones(inputs, K.shape(inputs)[-1]),\n",
        "                self.dropout,\n",
        "                training=training,\n",
        "                count=1)\n",
        "        if (0 < self.recurrent_dropout < 1 and\n",
        "                self._recurrent_masks is None):\n",
        "            _recurrent_mask = _generate_dropout_mask(\n",
        "                _generate_dropout_ones(inputs, self.units),\n",
        "                self.recurrent_dropout,\n",
        "                training=training,\n",
        "                count=1)\n",
        "            self._recurrent_masks = _recurrent_mask\n",
        "\n",
        "        # dropout matrices for input units\n",
        "        dp_mask = self._dropout_mask\n",
        "        # dropout matrices for recurrent units\n",
        "        rec_dp_masks = self._recurrent_masks\n",
        "\n",
        "        h_tm1 = states[0]  # previous state\n",
        "\n",
        "        if 0. < self.dropout < 1.:\n",
        "            inputs *= dp_mask[0]\n",
        "\n",
        "        if 0. < self.recurrent_dropout < 1.:\n",
        "            h_tm1 *= rec_dp_masks[0]\n",
        "\n",
        "        h = K.dot(inputs, self.kernel)\n",
        "        h = h + (h_tm1 * self.recurrent_kernel)\n",
        "\n",
        "        if self.use_bias:\n",
        "            h = K.bias_add(h, self.bias)\n",
        "\n",
        "        h = self.activation(h)\n",
        "\n",
        "        if 0 < self.dropout + self.recurrent_dropout:\n",
        "            if training is None:\n",
        "                h._uses_learning_phase = True\n",
        "        return h, [h]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'recurrent_clip_min': self.recurrent_clip_min,\n",
        "                  'recurrent_clip_max': self.recurrent_clip_max,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout,\n",
        "                  'implementation': self.implementation}\n",
        "        base_config = super(IndRNNCell, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class IndRNN(RNN):\n",
        "    \"\"\"Independently Recurrent Neural Networks Cell class.\n",
        "\n",
        "    Derived from the paper [Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN](https://arxiv.org/abs/1803.04831)\n",
        "    Ref: [Tensorflow implementation](https://github.com/batzner/indrnn)\n",
        "\n",
        "    # Arguments\n",
        "        units: Positive integer, dimensionality of the output space.\n",
        "        recurrent_clip_min: Can be one of None, -1 or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, computes the default clipping range for Relu activations\n",
        "        recurrent_clip_max: Can be one of None, -1 or float.\n",
        "            If None, clipping of weights will not take place.\n",
        "            If float, exact value will be used as clipping range\n",
        "            If -1, computes the default clipping range for Relu activations\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you pass None, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix,\n",
        "            used for the linear transformation of the inputs.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        recurrent_initializer: Initializer for the `recurrent_kernel`\n",
        "            weights matrix,\n",
        "            used for the linear transformation of the recurrent state.\n",
        "            (see [initializers](../initializers.md)).\n",
        "        bias_initializer: Initializer for the bias vector\n",
        "            (see [initializers](../initializers.md)).\n",
        "        unit_forget_bias: Boolean.\n",
        "            If True, add 1 to the bias of the forget gate at initialization.\n",
        "            Setting it to true will also force `bias_initializer=\"zeros\"`.\n",
        "            This is recommended in [Jozefowicz et al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        recurrent_regularizer: Regularizer function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        bias_regularizer: Regularizer function applied to the bias vector\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        activity_regularizer: Regularizer function applied to\n",
        "            the output of the layer (its \"activation\").\n",
        "            (see [regularizer](../regularizers.md)).\n",
        "        kernel_constraint: Constraint function applied to\n",
        "            the `kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        recurrent_constraint: Constraint function applied to\n",
        "            the `recurrent_kernel` weights matrix\n",
        "            (see [constraints](../constraints.md)).\n",
        "        bias_constraint: Constraint function applied to the bias vector\n",
        "            (see [constraints](../constraints.md)).\n",
        "        dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the inputs.\n",
        "        recurrent_dropout: Float between 0 and 1.\n",
        "            Fraction of the units to drop for\n",
        "            the linear transformation of the recurrent state.\n",
        "        implementation: Implementation mode, either 1 or 2.\n",
        "            Mode 1 will structure its operations as a larger number of\n",
        "            smaller dot products and additions, whereas mode 2 will\n",
        "            batch them into fewer, larger operations. These modes will\n",
        "            have different performance profiles on different hardware and\n",
        "            for different applications.\n",
        "        return_sequences: Boolean. Whether to return the last output.\n",
        "            in the output sequence, or the full sequence.\n",
        "        return_state: Boolean. Whether to return the last state\n",
        "            in addition to the output.\n",
        "        go_backwards: Boolean (default False).\n",
        "            If True, process the input sequence backwards and return the\n",
        "            reversed sequence.\n",
        "        stateful: Boolean (default False). If True, the last state\n",
        "            for each sample at index i in a batch will be used as initial\n",
        "            state for the sample of index i in the following batch.\n",
        "        unroll: Boolean (default False).\n",
        "            If True, the network will be unrolled,\n",
        "            else a symbolic loop will be used.\n",
        "            Unrolling can speed-up a RNN,\n",
        "            although it tends to be more memory-intensive.\n",
        "            Unrolling is only suitable for short sequences.\n",
        "\n",
        "    # References\n",
        "        - [Learning to forget: Continual prediction with NestedLSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)\n",
        "        - [Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)\n",
        "        - [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)\n",
        "        - [Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN](https://arxiv.org/abs/1803.04831)\n",
        "    \"\"\"\n",
        "\n",
        "    @interfaces.legacy_recurrent_support\n",
        "    def __init__(self, units,\n",
        "                 recurrent_clip_min=-1,\n",
        "                 recurrent_clip_max=-1,\n",
        "                 activation='relu',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 recurrent_initializer=None,\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 recurrent_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 recurrent_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 dropout=0.,\n",
        "                 recurrent_dropout=0.,\n",
        "                 implementation=2,\n",
        "                 return_sequences=False,\n",
        "                 return_state=False,\n",
        "                 go_backwards=False,\n",
        "                 stateful=False,\n",
        "                 unroll=False,\n",
        "                 **kwargs):\n",
        "        if implementation == 0:\n",
        "            warnings.warn('`implementation=0` has been deprecated, '\n",
        "                          'and now defaults to `implementation=2`.'\n",
        "                          'Please update your layer call.')\n",
        "        if K.backend() == 'theano':\n",
        "            warnings.warn(\n",
        "                'RNN dropout is no longer supported with the Theano backend '\n",
        "                'due to technical limitations. '\n",
        "                'You can either set `dropout` and `recurrent_dropout` to 0, '\n",
        "                'or use the TensorFlow backend.')\n",
        "            dropout = 0.\n",
        "            recurrent_dropout = 0.\n",
        "\n",
        "        cell = IndRNNCell(units,\n",
        "                          recurrent_clip_min=recurrent_clip_min,\n",
        "                          recurrent_clip_max=recurrent_clip_max,\n",
        "                          activation=activation,\n",
        "                          use_bias=use_bias,\n",
        "                          kernel_initializer=kernel_initializer,\n",
        "                          recurrent_initializer=recurrent_initializer,\n",
        "                          bias_initializer=bias_initializer,\n",
        "                          kernel_regularizer=kernel_regularizer,\n",
        "                          recurrent_regularizer=recurrent_regularizer,\n",
        "                          bias_regularizer=bias_regularizer,\n",
        "                          kernel_constraint=kernel_constraint,\n",
        "                          recurrent_constraint=recurrent_constraint,\n",
        "                          bias_constraint=bias_constraint,\n",
        "                          dropout=dropout,\n",
        "                          recurrent_dropout=recurrent_dropout,\n",
        "                          implementation=implementation)\n",
        "        super(IndRNN, self).__init__(cell,\n",
        "                                     return_sequences=return_sequences,\n",
        "                                     return_state=return_state,\n",
        "                                     go_backwards=go_backwards,\n",
        "                                     stateful=stateful,\n",
        "                                     unroll=unroll,\n",
        "                                     **kwargs)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        timesteps = input_shape[1]\n",
        "\n",
        "        if timesteps is None:\n",
        "            warnings.warn(\"Number of timesteps was not provided. If this model is being used for training purposes, \\n\"\n",
        "                          \"it is recommended to provide a finite number of timesteps when defining the input shape, \\n\"\n",
        "                          \"so as to initialize the weights of the recurrent kernel properly and avoid exploding gradients.\")\n",
        "\n",
        "        self.cell.timesteps = timesteps\n",
        "\n",
        "        super(IndRNN, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None, training=None, initial_state=None, constants=None):\n",
        "        self.cell._dropout_mask = None\n",
        "        self.cell._recurrent_masks = None\n",
        "        return super(IndRNN, self).call(inputs,\n",
        "                                        mask=mask,\n",
        "                                        training=training,\n",
        "                                        initial_state=initial_state,\n",
        "                                        constants=constants)\n",
        "\n",
        "    @property\n",
        "    def units(self):\n",
        "        return self.cell.units\n",
        "\n",
        "    @property\n",
        "    def recurrent_clip_min(self):\n",
        "        return self.cell.recurrent_clip_min\n",
        "\n",
        "    @property\n",
        "    def recurrent_clip_max(self):\n",
        "        return self.cell.recurrent_clip_max\n",
        "\n",
        "    @property\n",
        "    def activation(self):\n",
        "        return self.cell.activation\n",
        "\n",
        "    @property\n",
        "    def use_bias(self):\n",
        "        return self.cell.use_bias\n",
        "\n",
        "    @property\n",
        "    def kernel_initializer(self):\n",
        "        return self.cell.kernel_initializer\n",
        "\n",
        "    @property\n",
        "    def recurrent_initializer(self):\n",
        "        return self.cell.recurrent_initializer\n",
        "\n",
        "    @property\n",
        "    def bias_initializer(self):\n",
        "        return self.cell.bias_initializer\n",
        "\n",
        "    @property\n",
        "    def kernel_regularizer(self):\n",
        "        return self.cell.kernel_regularizer\n",
        "\n",
        "    @property\n",
        "    def recurrent_regularizer(self):\n",
        "        return self.cell.recurrent_regularizer\n",
        "\n",
        "    @property\n",
        "    def bias_regularizer(self):\n",
        "        return self.cell.bias_regularizer\n",
        "\n",
        "    @property\n",
        "    def kernel_constraint(self):\n",
        "        return self.cell.kernel_constraint\n",
        "\n",
        "    @property\n",
        "    def recurrent_constraint(self):\n",
        "        return self.cell.recurrent_constraint\n",
        "\n",
        "    @property\n",
        "    def bias_constraint(self):\n",
        "        return self.cell.bias_constraint\n",
        "\n",
        "    @property\n",
        "    def dropout(self):\n",
        "        return self.cell.dropout\n",
        "\n",
        "    @property\n",
        "    def recurrent_dropout(self):\n",
        "        return self.cell.recurrent_dropout\n",
        "\n",
        "    @property\n",
        "    def implementation(self):\n",
        "        return self.cell.implementation\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'recurrent_clip_min': self.recurrent_clip_min,\n",
        "                  'recurrent_clip_max': self.recurrent_clip_max,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "                  'recurrent_initializer': initializers.serialize(self.recurrent_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "                  'recurrent_regularizer': regularizers.serialize(self.recurrent_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'recurrent_constraint': constraints.serialize(self.recurrent_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'dropout': self.dropout,\n",
        "                  'recurrent_dropout': self.recurrent_dropout,\n",
        "                  'implementation': self.implementation}\n",
        "        base_config = super(IndRNN, self).get_config()\n",
        "        del base_config['cell']\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        if 'implementation' in config and config['implementation'] == 0:\n",
        "            config['implementation'] = 2\n",
        "        return cls(**config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHPCzS3K5PUt",
        "outputId": "5701949f-b15e-4902-9c25-f2dfeda92068"
      },
      "source": [
        "# run this cell if you are using colab\n",
        "# connecting to google drive. this is necessary for load file from google drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Loading .Mat data from google drive\n",
        "\n",
        "import scipy.io\n",
        "mat_file_path = '/content/drive/MyDrive/EEG_Hackathon/shamdata_tlgo.mat'\n",
        "\n",
        "mat_raw_data = scipy.io.loadmat(mat_file_path)\n",
        "mat_data = {k:v for k, v in mat_raw_data.items() if k[0] != '_'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR0TZzxB5g9y"
      },
      "source": [
        "# set variables\n",
        "\n",
        "used_batch_of_participant = 'shamhceeg'\n",
        "# used_batch_of_participant = 'hcoffmed'\n",
        "\n",
        "participant_to_ignore_in_batch = [7,8,9,13]\n",
        "participant_for_test_in_batch = [] # consider that some participant is removed before --- consider that you can not make test array in both participant and trial base\n",
        "trial_index_for_test_in_each_participant = [1] # consider that you can not make test array in both participant and trial base\n",
        "start_timepoint_for_X = 1000\n",
        "number_of_timepoint_for_X = 500\n",
        "number_of_timepoint_for_Y = 1\n",
        "periods_of_Y_timepoint_for_predict = 600\n",
        "x_test_to_total_x_ratio = 0.10\n",
        "channel_index_for_ignore = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBhfFpm95ncK",
        "outputId": "8a837d78-c3d7-4702-cba2-e91637b9dd3f"
      },
      "source": [
        "# load data for a batch and delete some participant with defective data\n",
        "\n",
        "import numpy as np\n",
        "data_for_a_batch = mat_data[used_batch_of_participant]\n",
        "\n",
        "data_for_a_batch = np.delete(data_for_a_batch, participant_to_ignore_in_batch , 1) # delete some participant with defective data\n",
        "#data_for_a_batch=data_for_a_batch[:,999:2000,:]\n",
        "\n",
        "print(type(data_for_a_batch))\n",
        "print(data_for_a_batch.shape)\n",
        "\n",
        "print(type(data_for_a_batch[0]))\n",
        "print(data_for_a_batch[0].shape)\n",
        "\n",
        "print(type(data_for_a_batch[0][0]))\n",
        "print(data_for_a_batch[0][0].shape)\n",
        "\n",
        "print(type(data_for_a_batch[0][0][0]))\n",
        "print(data_for_a_batch[0][0][0].shape)\n",
        "\n",
        "# data_for_a_batch[0][0][0][0]= np.array(data_for_a_batch[0][0][0][0])\n",
        "print(type(data_for_a_batch[0][0][0][1]))\n",
        "print(data_for_a_batch[0][0][0][0].shape)\n",
        "\n",
        "# print(data_for_a_batch[0][0][0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<type 'numpy.ndarray'>\n",
            "(1, 18)\n",
            "<type 'numpy.ndarray'>\n",
            "(18,)\n",
            "<type 'numpy.ndarray'>\n",
            "(27, 2000, 10)\n",
            "<type 'numpy.ndarray'>\n",
            "(2000, 10)\n",
            "<type 'numpy.ndarray'>\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A62vFC-W5qYb"
      },
      "source": [
        "# calculate some needed variables\n",
        "\n",
        "number_of_participant_in_batch = len(mat_data[used_batch_of_participant][0])\n",
        "number_of_usable_participant = number_of_participant_in_batch - len(participant_to_ignore_in_batch)\n",
        "number_of_tiral_for_each_participant = len(data_for_a_batch[0][0][0][0])\n",
        "number_of_total_tiral = number_of_tiral_for_each_participant * number_of_usable_participant\n",
        "# print(number_of_participant_in_batch)\n",
        "number_of_tiral_for_test_for_each_participant = len(trial_index_for_test_in_each_participant)\n",
        "number_of_tiral_for_train_for_each_participant = number_of_tiral_for_each_participant - number_of_tiral_for_test_for_each_participant\n",
        "\n",
        "number_of_total_timepoint_of_a_trial = len(data_for_a_batch[0][0][1])\n",
        "number_of_signal_channel = len(data_for_a_batch[0][0])\n",
        "number_of_signal_channel_in_use = number_of_signal_channel - len(channel_index_for_ignore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BzPxjbm5s4t",
        "outputId": "3f9eec29-92f5-407a-c54d-a0b984a20850"
      },
      "source": [
        "# reform data to [total trial] * [timepoint] * [signal channel]\n",
        "\n",
        "reformed_data_for_a_batch = [0 for counter in range(number_of_total_tiral)]\n",
        "\n",
        "for usable_participant_counter in range(number_of_usable_participant):\n",
        "  for tiral_for_each_participant_counter in range(number_of_tiral_for_each_participant):\n",
        "    in_total_trial_counter = usable_participant_counter * number_of_tiral_for_each_participant + tiral_for_each_participant_counter\n",
        "    one_trial_data_matrix = [[0  for channel_counter in range(number_of_signal_channel)]for timepoint_counter in range(number_of_total_timepoint_of_a_trial)]\n",
        "    for channel_counter in range(number_of_signal_channel):\n",
        "      for timepoint_counter in range(number_of_total_timepoint_of_a_trial):\n",
        "        one_trial_data_matrix[timepoint_counter][channel_counter] = float(data_for_a_batch[0][usable_participant_counter][channel_counter][timepoint_counter][tiral_for_each_participant_counter])\n",
        "    reformed_data_for_a_batch[in_total_trial_counter] = one_trial_data_matrix\n",
        "\n",
        "print(type(reformed_data_for_a_batch))\n",
        "print(len(reformed_data_for_a_batch))\n",
        "\n",
        "print(type(reformed_data_for_a_batch[0]))\n",
        "print(len(reformed_data_for_a_batch[0]))\n",
        "\n",
        "print(type(reformed_data_for_a_batch[0][0]))\n",
        "print(len(reformed_data_for_a_batch[0][0]))\n",
        "\n",
        "print(type(reformed_data_for_a_batch[0][0][0]))\n",
        "print(reformed_data_for_a_batch[0][0][0])\n",
        "print(max(np.array(reformed_data_for_a_batch)[1 , : , 0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<type 'list'>\n",
            "180\n",
            "<type 'list'>\n",
            "2000\n",
            "<type 'list'>\n",
            "27\n",
            "<type 'float'>\n",
            "2.93364968017\n",
            "18.638614956188313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi0MFoy85v6y",
        "outputId": "41b79fed-fe2c-4aa8-ff37-db60ead663b0"
      },
      "source": [
        "# normalize data between 0 and 1 for each channel\n",
        "\n",
        "normalized_reformed_data_for_a_batch = reformed_data_for_a_batch\n",
        "\n",
        "from pandas import DataFrame\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "for counter in range(number_of_total_tiral):\n",
        "  df = DataFrame(reformed_data_for_a_batch[counter])\n",
        "  df = df.fillna(0)\n",
        "  normalized_reformed_data_for_a_batch[counter] = scaler.fit_transform(df)\n",
        "\n",
        "normalized_reformed_data_for_a_batch = np.array(normalized_reformed_data_for_a_batch)\n",
        "\n",
        "print(type(normalized_reformed_data_for_a_batch))\n",
        "print(len(normalized_reformed_data_for_a_batch))\n",
        "print(type(normalized_reformed_data_for_a_batch[0]))\n",
        "print(len(normalized_reformed_data_for_a_batch[0]))\n",
        "print(type(normalized_reformed_data_for_a_batch[0][0]))\n",
        "print(len(normalized_reformed_data_for_a_batch[0][0]))\n",
        "print(type(normalized_reformed_data_for_a_batch[0][0][0]))\n",
        "print(normalized_reformed_data_for_a_batch[0][0][0])\n",
        "\n",
        "import numpy as np\n",
        "print(min(np.array(normalized_reformed_data_for_a_batch)[0 , : , 0]))\n",
        "print(max(np.array(normalized_reformed_data_for_a_batch)[0 , : , 0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<type 'numpy.ndarray'>\n",
            "180\n",
            "<type 'numpy.ndarray'>\n",
            "2000\n",
            "<type 'numpy.ndarray'>\n",
            "27\n",
            "<type 'numpy.float64'>\n",
            "0.6727521908553735\n",
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWmVj2NY5zN2",
        "outputId": "4aff29e4-57c3-4a3f-cff0-fdd5a8e332b1"
      },
      "source": [
        "# delete signal channel that are planed to ignore\n",
        "\n",
        "normalized_reformed_data_for_a_batch = np.delete(normalized_reformed_data_for_a_batch, channel_index_for_ignore , 2)\n",
        "\n",
        "print(type(normalized_reformed_data_for_a_batch))\n",
        "print(len(normalized_reformed_data_for_a_batch))\n",
        "print(type(normalized_reformed_data_for_a_batch[0]))\n",
        "print(len(normalized_reformed_data_for_a_batch[0]))\n",
        "print(type(normalized_reformed_data_for_a_batch[0][0]))\n",
        "print(len(normalized_reformed_data_for_a_batch[0][0]))\n",
        "print(type(normalized_reformed_data_for_a_batch[0][0][0]))\n",
        "print(normalized_reformed_data_for_a_batch[0][0][0])\n",
        "print(number_of_signal_channel_in_use)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<type 'numpy.ndarray'>\n",
            "180\n",
            "<type 'numpy.ndarray'>\n",
            "2000\n",
            "<type 'numpy.ndarray'>\n",
            "1\n",
            "<type 'numpy.float64'>\n",
            "0.8476729826692428\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgxJrgLN52vi",
        "outputId": "a16942e3-e1d6-496a-8761-533e2a630440"
      },
      "source": [
        "# make test trial arrays and update train trials\n",
        "\n",
        "test_participant_trial = []\n",
        "if len(participant_for_test_in_batch) != 0:\n",
        "  print(\"participant base test collection\")\n",
        "  for counter in range(len(participant_for_test_in_batch)):\n",
        "    start_trial_for_this_participant = participant_for_test_in_batch[counter] * number_of_tiral_for_each_participant\n",
        "    end_trial_for_this_participant = start_trial_for_this_participant + number_of_tiral_for_each_participant\n",
        "    print(start_trial_for_this_participant)\n",
        "    print(end_trial_for_this_participant)\n",
        "    to_append_list = normalized_reformed_data_for_a_batch[start_trial_for_this_participant:end_trial_for_this_participant]\n",
        "    print(len(to_append_list))\n",
        "    for list_element in to_append_list:\n",
        "      test_participant_trial.append(list_element)\n",
        "\n",
        "  to_delete_list = []\n",
        "  for counter in range(len(participant_for_test_in_batch)):\n",
        "    for trial_counter in range(participant_for_test_in_batch[counter]* number_of_tiral_for_each_participant ,participant_for_test_in_batch[counter]* number_of_tiral_for_each_participant+number_of_tiral_for_each_participant):\n",
        "      to_delete_list.append(trial_counter)\n",
        "\n",
        "  print(to_delete_list)\n",
        "  normalized_reformed_data_for_a_batch = np.delete(normalized_reformed_data_for_a_batch, to_delete_list , 0)\n",
        "\n",
        "################################### Trial Out ##########################################\n",
        "\n",
        "if len(trial_index_for_test_in_each_participant)!=0:\n",
        "  print(\"trial base test collection\")\n",
        "  for counter_in_participant in range(number_of_usable_participant):\n",
        "    index_for_test_in_this_participant = [trial_index_for_test_in_each_participant[i] + (counter_in_participant * number_of_tiral_for_each_participant) for i in range(len(trial_index_for_test_in_each_participant))]\n",
        "    print(index_for_test_in_this_participant)\n",
        "    to_append_list = normalized_reformed_data_for_a_batch[index_for_test_in_this_participant]\n",
        "    for list_element in to_append_list:\n",
        "      test_participant_trial.append(list_element)\n",
        "\n",
        "  to_delete_list = []\n",
        "  for counter_in_participant in range(number_of_usable_participant):\n",
        "    index_for_test_in_this_participant = [trial_index_for_test_in_each_participant[i] + (counter_in_participant * number_of_tiral_for_each_participant) for i in range(len(trial_index_for_test_in_each_participant))]\n",
        "    print(index_for_test_in_this_participant)\n",
        "    to_delete_list.append(index_for_test_in_this_participant)\n",
        "\n",
        "  print(to_delete_list)\n",
        "  normalized_reformed_data_for_a_batch = np.delete(normalized_reformed_data_for_a_batch, to_delete_list , 0)\n",
        "\n",
        "test_participant_trial = np.array(test_participant_trial)\n",
        "\n",
        "print(test_participant_trial.shape)\n",
        "print(type(test_participant_trial))\n",
        "print(test_participant_trial[0].shape)\n",
        "print(type(test_participant_trial[0]))\n",
        "print(test_participant_trial[0][0].shape)\n",
        "print(type(test_participant_trial[0][0]))\n",
        "print(test_participant_trial[0][0][0])\n",
        "print(type(test_participant_trial[0][0][0]))\n",
        "\n",
        "print(type(normalized_reformed_data_for_a_batch))\n",
        "print(len(normalized_reformed_data_for_a_batch))\n",
        "print(type(normalized_reformed_data_for_a_batch[0]))\n",
        "print(len(normalized_reformed_data_for_a_batch[0]))\n",
        "print(type(normalized_reformed_data_for_a_batch[0][0]))\n",
        "print(len(normalized_reformed_data_for_a_batch[0][0]))\n",
        "print(type(normalized_reformed_data_for_a_batch[0][0][0]))\n",
        "print(normalized_reformed_data_for_a_batch[0][0][0])\n",
        "\n",
        "print(min(np.array(normalized_reformed_data_for_a_batch)[0 , : , 0]))\n",
        "print(max(np.array(normalized_reformed_data_for_a_batch)[0 , : , 0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trial base test collection\n",
            "[1]\n",
            "[11]\n",
            "[21]\n",
            "[31]\n",
            "[41]\n",
            "[51]\n",
            "[61]\n",
            "[71]\n",
            "[81]\n",
            "[91]\n",
            "[101]\n",
            "[111]\n",
            "[121]\n",
            "[131]\n",
            "[141]\n",
            "[151]\n",
            "[161]\n",
            "[171]\n",
            "[1]\n",
            "[11]\n",
            "[21]\n",
            "[31]\n",
            "[41]\n",
            "[51]\n",
            "[61]\n",
            "[71]\n",
            "[81]\n",
            "[91]\n",
            "[101]\n",
            "[111]\n",
            "[121]\n",
            "[131]\n",
            "[141]\n",
            "[151]\n",
            "[161]\n",
            "[171]\n",
            "[[1], [11], [21], [31], [41], [51], [61], [71], [81], [91], [101], [111], [121], [131], [141], [151], [161], [171]]\n",
            "(18, 2000, 1)\n",
            "<type 'numpy.ndarray'>\n",
            "(2000, 1)\n",
            "<type 'numpy.ndarray'>\n",
            "(1,)\n",
            "<type 'numpy.ndarray'>\n",
            "0.386382428130307\n",
            "<type 'numpy.float64'>\n",
            "<type 'numpy.ndarray'>\n",
            "162\n",
            "<type 'numpy.ndarray'>\n",
            "2000\n",
            "<type 'numpy.ndarray'>\n",
            "1\n",
            "<type 'numpy.float64'>\n",
            "0.8476729826692428\n",
            "0.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VlEx0Wu59B5"
      },
      "source": [
        "# update some numbers\n",
        "\n",
        "number_of_total_tiral_for_train = len(normalized_reformed_data_for_a_batch)\n",
        "number_of_total_tiral_for_test = len(test_participant_trial)\n",
        "\n",
        "number_of_separable_X_in_a_trial = (number_of_total_timepoint_of_a_trial - number_of_timepoint_for_X) // number_of_timepoint_for_Y\n",
        "number_of_total_separable_X = number_of_separable_X_in_a_trial * number_of_total_tiral_for_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRRw9CC-6AcB",
        "outputId": "dc936a5f-1955-4878-ba80-cb56c0ed353a"
      },
      "source": [
        "# make separable X & Y from data\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for trial_counter in range(number_of_total_tiral_for_train):\n",
        "  for counter in range(number_of_separable_X_in_a_trial):\n",
        "    start_point_for_x = counter * number_of_timepoint_for_Y \n",
        "    end_point_for_x = start_point_for_x + number_of_timepoint_for_X\n",
        "    start_point_for_y = end_point_for_x - 100\n",
        "    end_point_for_y = start_point_for_y + number_of_timepoint_for_Y\n",
        "    #start_point_for_xtest = end_point_for_y-1\n",
        "    #end_point_for_xtest = start_point_for_xtest + periods_of_Y_timepoint_for_predict\n",
        "    #start_point_for_ytest = start_point_for_xtest+1\n",
        "    #end_point_for_ytest = start_point_for_ytest + 500\n",
        "    separable_X = normalized_reformed_data_for_a_batch[trial_counter][start_point_for_x:end_point_for_x][:]\n",
        "    separable_Y = normalized_reformed_data_for_a_batch[trial_counter][start_point_for_y:end_point_for_y][:]\n",
        "    X.append(separable_X)\n",
        "    Y.append(separable_Y)\n",
        "\n",
        "    #separable_Xtest = normalized_reformed_data_for_a_batch[trial_counter][start_point_for_xtest:end_point_for_xtest][:]\n",
        "    #separable_Ytest = normalized_reformed_data_for_a_batch[trial_counter][start_point_for_ytest:end_point_for_ytest][:]\n",
        "    #Xtest.append(separable_Xtest)\n",
        "    #Ytest.append(separable_Ytest)\n",
        "\n",
        "print(len(X))\n",
        "print(len(Y))\n",
        "print(len(X[0]))\n",
        "print(len(Y[0]))\n",
        "print(len(X[0][0]))\n",
        "print(len(Y[0][0]))\n",
        "\n",
        "#print(len(Xtest))\n",
        "#print(len(Ytest))\n",
        "#print(len(Xtest[0]))\n",
        "#print(len(Ytest[0]))\n",
        "#print(len(Xtest[0][0]))\n",
        "#print(len(Ytest[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "243000\n",
            "243000\n",
            "500\n",
            "1\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soC-fOjR6DDh",
        "outputId": "c0e247fc-9492-45c2-879c-942458804641"
      },
      "source": [
        "# convert data to numpy array\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np_X = np.array(X)\n",
        "np_Y = np.array(Y)\n",
        "\n",
        "\n",
        "print(np_X.shape)\n",
        "\n",
        "print(type(np_X))\n",
        "print(len(np_X))\n",
        "\n",
        "print(type(np_X[0]))\n",
        "print(len(np_X[0]))\n",
        "\n",
        "print(type(np_X[0][0]))\n",
        "print(len(np_X[0][0]))\n",
        "\n",
        "print(type(np_X[0][0][0]))\n",
        "print(np_X[0][0][0])\n",
        "\n",
        "\n",
        "print(np_Y.shape)\n",
        "\n",
        "print(type(np_Y))\n",
        "print(len(np_Y))\n",
        "\n",
        "print(type(np_Y[0]))\n",
        "print(len(np_Y[0]))\n",
        "\n",
        "print(type(np_Y[0][0]))\n",
        "print(len(np_Y[0][0]))\n",
        "\n",
        "print(type(np_Y[0][0][0]))\n",
        "print(np_Y[0][0][0])\n",
        "\n",
        "\n",
        "\n",
        "#np_Xtest = np.array(Xtest)\n",
        "#np_Ytest = np.array(Ytest)\n",
        "\n",
        "\n",
        "#print(np_Xtest.shape)\n",
        "\n",
        "#print(type(np_Xtest))\n",
        "#print(len(np_Xtest))\n",
        "\n",
        "#print(type(np_Xtest[0]))\n",
        "#print(len(np_Xtest[0]))\n",
        "\n",
        "#print(type(np_Xtest[0][0]))\n",
        "#print(len(np_Xtest[0][0]))\n",
        "\n",
        "#print(type(np_Xtest[0][0][0]))\n",
        "#print(np_Xtest[0][0][0])\n",
        "\n",
        "\n",
        "#print(np_Ytest.shape)\n",
        "\n",
        "#print(type(np_Ytest))\n",
        "#print(len(np_Ytest))\n",
        "\n",
        "#print(type(np_Ytest[0]))\n",
        "#print(len(np_Ytest[0]))\n",
        "\n",
        "#print(type(np_Ytest[0][0]))\n",
        "#print(len(np_Ytest[0][0]))\n",
        "\n",
        "#print(type(np_Ytest[0][0][0]))\n",
        "#print(np_Ytest[0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(243000, 500, 1)\n",
            "<type 'numpy.ndarray'>\n",
            "243000\n",
            "<type 'numpy.ndarray'>\n",
            "500\n",
            "<type 'numpy.ndarray'>\n",
            "1\n",
            "<type 'numpy.float64'>\n",
            "0.8476729826692428\n",
            "(243000, 1, 1)\n",
            "<type 'numpy.ndarray'>\n",
            "243000\n",
            "<type 'numpy.ndarray'>\n",
            "1\n",
            "<type 'numpy.ndarray'>\n",
            "1\n",
            "<type 'numpy.float64'>\n",
            "0.7249160263135014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "XSq94LWk6FkR",
        "outputId": "60568a14-08ac-427b-8949-b8077e62d6a4"
      },
      "source": [
        "# plot an example from input\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "timepoint_for_plot_X = range(0, number_of_timepoint_for_X)\n",
        "timepoint_for_plot_Y = range(number_of_timepoint_for_X, number_of_timepoint_for_X + number_of_timepoint_for_Y)\n",
        "\n",
        "fig, ax = plt.subplots(number_of_signal_channel_in_use, 1)\n",
        "fig.suptitle('blue line for X and orange line for Y for a sample participant')\n",
        "fig.set_size_inches(10, 10)\n",
        "\n",
        "for channel_counter in range(number_of_signal_channel_in_use):\n",
        "  if number_of_signal_channel_in_use>1:\n",
        "    ax[channel_counter].plot(timepoint_for_plot_X, np_X[0 , : , channel_counter])\n",
        "    ax[channel_counter].plot(timepoint_for_plot_Y, np_Y[0 , : , channel_counter])\n",
        "  else:\n",
        "    ax.plot(timepoint_for_plot_X, np_X[0 , : , channel_counter])\n",
        "   # ax.plot(timepoint_for_plot_Y, np_Y[0 , : , channel_counter])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGo4iw2y6HuO",
        "outputId": "c1c357db-7d20-432d-a30c-107769609ba0"
      },
      "source": [
        "# reshape Y from 2-D to 1-D\n",
        "\n",
        "np_Y_flat = np_Y.reshape(number_of_total_separable_X ,number_of_timepoint_for_Y*number_of_signal_channel_in_use)\n",
        "\n",
        "print(np_Y_flat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(243000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3kn1kit6K1d",
        "outputId": "673211ac-f645-42b3-8ac5-c03687bd2ece"
      },
      "source": [
        "# split X & Y to train & test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_X, np_Y_flat, test_size=x_test_to_total_x_ratio)\n",
        "x_test_no_touch = x_test\n",
        "\n",
        "print(len(X))\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))\n",
        "\n",
        "print(len(Y))\n",
        "print(len(y_train[0]))\n",
        "print(len(y_test[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "243000\n",
            "218700\n",
            "24300\n",
            "218700\n",
            "24300\n",
            "243000\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pr9otDlr6t8w",
        "outputId": "67a405f3-966a-420d-a484-1a4110c2e97d"
      },
      "source": [
        "# make model\n",
        "hidden_units = 24\n",
        "\n",
        "cells = [IndRNNCell(hidden_units),\n",
        "         IndRNNCell(hidden_units)]\n",
        "# !pip install keras\n",
        "# !pip install tensorflow\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import AveragePooling1D\n",
        "from keras.layers import Flatten\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(RNN(cells, return_sequences=True, input_shape = (number_of_timepoint_for_X , number_of_signal_channel_in_use)))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(150, input_shape = (number_of_timepoint_for_X , number_of_signal_channel_in_use)))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "# model.add(Dropout(0.1))\n",
        "# model.add(AveragePooling1D(50))\n",
        "model.add(Flatten())\n",
        "# model.add(Dropout(0.1))\n",
        "# model.add(Dense(1))\n",
        "model.add(Dense(number_of_signal_channel_in_use*number_of_timepoint_for_Y))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python2.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.16.4)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.post1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: scipy==1.2.2; python_version < \"3\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.2.2)\n",
            "Requirement already satisfied: wheel; python_version < \"3\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: mock>=2.0.0; python_version < \"3\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.0.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: functools32>=3.2.3; python_version < \"3\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (3.2.3.post2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.3.2)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.1.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.8.0->tensorflow) (44.1.1)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0; python_version < \"3\"->tensorflow) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0; python_version < \"3\"->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.15.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.30.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.5)\n",
            "Requirement already satisfied: rsa<4.6; python_version < \"3.6\" in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.6.16)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python2.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.5)\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth-oauthlib\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "  Found existing installation: google-auth-oauthlib 0.4.0\n",
            "    Uninstalling google-auth-oauthlib-0.4.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.0\n",
            "Successfully installed google-auth-oauthlib-0.4.1 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:142: UserWarning: IndRNNCell: Number of timesteps could not be determined. \n",
            "Defaulting to max clipping range of 1.0. \n",
            "If this model was trained using a specific timestep during training, inference may be wrong due to this default setting.\n",
            "Please ensure that you use the same number of timesteps during training and evaluation\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rnn_1 (RNN)                  (None, 500, 24)           696       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 500, 1)            25        \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 501       \n",
            "=================================================================\n",
            "Total params: 1,222\n",
            "Trainable params: 1,222\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlm1as4V7xOd"
      },
      "source": [
        "# from keras.optimizers import Adam\n",
        "# learning_rate = 1e-3\n",
        "\n",
        "# rmsprop = Adam(lr=learning_rate, amsgrad=True)\n",
        "\n",
        "# model.compile(loss='sparse_categorical_crossentropy',\n",
        "#               optimizer=rmsprop,\n",
        "#               metrics=['accuracy'])\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='mae', optimizer= Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEzpk1Eu8nDb",
        "outputId": "aa45072c-e36d-469d-8a63-6088dd725b11"
      },
      "source": [
        "# train model\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs= 20, batch_size=100 ,validation_data= (x_test, y_test), verbose=1, shuffle=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 218700 samples, validate on 24300 samples\n",
            "Epoch 1/20\n",
            "126100/218700 [================>.............] - ETA: 6:35 - loss: 0.1137 - accuracy: 9.5163e-04"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93D6kfCREn3M"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "input_X_for_test = test_participant_trial[: , 0:number_of_timepoint_for_X , :]\n",
        "for_store_predicted_X = test_participant_trial[: , 0:number_of_timepoint_for_X , :]\n",
        "end_point_for_prediction = number_of_timepoint_for_X + periods_of_Y_timepoint_for_predict*number_of_timepoint_for_Y\n",
        "original_X_for_plot = test_participant_trial[: , 0:end_point_for_prediction , :]\n",
        "for time_period_counter in range(periods_of_Y_timepoint_for_predict):\n",
        "  y_pred=model.predict(input_X_for_test)\n",
        "  reshaped_y_pred = y_pred.reshape(len(input_X_for_test) , number_of_timepoint_for_Y , number_of_signal_channel_in_use)\n",
        "  for_store_predicted_X =np.concatenate((for_store_predicted_X, reshaped_y_pred), axis=1)\n",
        "  temp_input_X_for_test = np.concatenate((input_X_for_test, reshaped_y_pred), axis=1)\n",
        "  # print(temp_input_X_for_test.shape)\n",
        "  # print(for_store_predicted_X.shape)\n",
        "  input_X_for_test = np.delete(temp_input_X_for_test, np.s_[0:number_of_timepoint_for_Y:], 1)\n",
        "\n",
        "for_store_predicted_X = np.delete(for_store_predicted_X, np.s_[0:number_of_timepoint_for_X:], 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEL4QvI1ErLE"
      },
      "source": [
        "# plot predicted vs original\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "timepoint_for_plot_original_X = range(0, end_point_for_prediction)\n",
        "# timepoint_for_plot_first_input_X = range(0, number_of_timepoint_for_X)\n",
        "timepoint_for_plot_predicted_X = range(number_of_timepoint_for_X, end_point_for_prediction)\n",
        "RMSE = mean_squared_error(original_X_for_plot[0 , 1400: , channel_counter], for_store_predicted_X[0 , : , channel_counter])\n",
        "RMSE1 = \"{:.8f}\".format(RMSE)\n",
        "print(RMSE1)\n",
        "R2 = r2_score(original_X_for_plot[0 , 1400: , channel_counter], for_store_predicted_X[0 , : , channel_counter])\n",
        "print(R2)\n",
        "#Rsquared=1-(RMSE1/mean_squared_error(original_X_for_plot[0 , 1700: , channel_counter],mean(original_X_for_plot[0 , 1700: , channel_counter])))\n",
        "#print(Rsquared)\n",
        "fig, axis = plt.subplots(number_of_signal_channel_in_use, 1)\n",
        "fig.suptitle('text')\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "for channel_counter in range(number_of_signal_channel_in_use):\n",
        "  if number_of_signal_channel_in_use>1:\n",
        "    axis[channel_counter].plot(timepoint_for_plot_original_X[:2000], original_X_for_plot[0 , : , channel_counter] ,label = 'real value')\n",
        "    axis[channel_counter].plot(timepoint_for_plot_predicted_X, for_store_predicted_X[0 , : , channel_counter] ,label= 'prediction')\n",
        "  else:\n",
        "    axis.plot(timepoint_for_plot_original_X[:2000], original_X_for_plot[0 , : , channel_counter] , label = 'real value')\n",
        "    axis.plot(timepoint_for_plot_predicted_X, for_store_predicted_X[0 , : , channel_counter] , label= 'prediction')\n",
        "  \n",
        "plt.title('CNN + LSTM with MAE Loss Function, Adam optimizer. Unseen Data= [17] , Num of Channel = [14]')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
